import pandas as pd
import json
import os

# Define directories
evaluation_dir = "/Users/mateodib/Desktop/Environmental_News_Checker-2/Data/resultats/resultats_intermediaires/evaluation_parsed/"
article_dir = "/Users/mateodib/Desktop/Environmental_News_Checker-2/Data/presse/articles_chunked/"
output_dir = "/Users/mateodib/Desktop/Environmental_News_Checker-2/Data/resultats/resultats_intermediaires/articles_json/"
os.makedirs(output_dir, exist_ok=True)  # Create output directory if it doesn't exist

# Loop through each evaluation file in the directory
for filename in os.listdir(evaluation_dir):
    if filename.endswith("_parsed.csv"):
        # Paths for the evaluation file and output JSON
        chemin_evaluation_parsed = os.path.join(evaluation_dir, filename)
        output_json_path = os.path.join(output_dir, f"{os.path.splitext(filename)[0]}.json")

        # Load the evaluation data with fact-checked chunks
        df_evaluation_parsed = pd.read_csv(chemin_evaluation_parsed)
        
        
        # Determine the corresponding article file path based on the evaluation file name
        article_filename = filename.replace("_evaluation_results_parsed.csv", "_analysis_results.csv")
        chemin_article = os.path.join(article_dir, article_filename)

        # Check if the article file exists
        if not os.path.exists(chemin_article):
            print(f"Article file {chemin_article} not found. Skipping.")
            continue

        # Load the climate analysis data with all chunks of 3 sentences
        df_climate_analysis = pd.read_csv(chemin_article)

        # Merge evaluation data with climate analysis data on "id"
        df_merged = df_climate_analysis.merge(df_evaluation_parsed.drop(columns=['current_phrase']), on="id", how="left")

        # Extract the article title from the file name (remove path and extension)
        article_title = os.path.splitext(article_filename)[0]

        # Initialize a dictionary to store structured JSON data
        structured_data = {
            "article_title": article_title,
            "phrases": {}
        }

        # Iterate over the merged DataFrame to build the structured JSON data
        for _, row in df_merged.iterrows():
            # Prepare analysis data for each metric, using dictionary comprehension for simplicity
            analysis_data = {
                metric: {
                    "score": row[f"{metric}_score"] if pd.notna(row[f"{metric}_score"]) else None,
                    "justifications": row[f"{metric}_justification"] if pd.notna(row[f"{metric}_justification"]) else None
                }
                for metric in ["accuracy", "bias", "tone", "clarity", "completeness", "objectivity", "alignment"]
            }

            # Prepare phrase data
            phrase_data = {
                "text": row['current_phrase'] if 'current_phrase' in row else None,
                "context": row['context'] if 'context' in row else None,
                "analysis": analysis_data
            }

            # Add the phrase data to the JSON structure under its "id" as the key
            structured_data["phrases"][str(row['id'])] = phrase_data

        # Save the structured data as JSON
        with open(output_json_path, 'w', encoding='utf-8') as json_file:
            json.dump(structured_data, json_file, indent=4, ensure_ascii=False)

        print(f"Structured article analysis saved to {output_json_path}")